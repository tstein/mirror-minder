#!/usr/bin/env python
"""Continuously monitor Termux repo mirrors for freshness. Files Github issues if the
data being vended by a mirror falls too far behind the authoritative mirrors we
initially push to, as well as if we are unable to confirm that a mirror is up to date
due to durable availability or parsing issues.

Determines the list of repos to monitor on startup and holds them forever, and does not
cache any info about mirror freshness between runs.

Major TODOs:
  * Alert if this program's is unable to maintain current knowledge of the authoritative
    repos.
  * Alert on logic bugs.
Potentially worthwhile upgrades:
  * Handle updates to the mirror list mid-run.
  * Auto-resolve the issues it creates when possible.
"""

import argparse
import logging
import os
import os.path
import random
import time
import urllib3
from dataclasses import dataclass
from datetime import datetime, timedelta, UTC
from typing import Optional

import requests
import sh
from sh import git

from issues import list_open_issues, open_new_issue

############################
# hard-coded configuration #
############################
TERMUX_TOOLS_REPO = "termux-tools"
# Approximately how long to wait after startup before the initial checks of each mirror.
INITIAL_CHECK_DELAY = timedelta(seconds=30)
# Approximately how long to wait between checks after the initial round.
CHECK_INTERVAL = timedelta(minutes=30)
CHECK_JITTER_FRACTION = .05

STALENESS_LIMIT = timedelta(days=3)
CONSECUTIVE_FAIL_LIMIT = round(timedelta(days=3) / CHECK_INTERVAL)
RELEASE_RETRIEVAL_LIMIT_S = 120

REPORTING_REPO = "https://github.com/tstein/mirror-minder"
ISSUE_TITLE_TEMPLATE = "mirror unhealthy: {}"
ISSUE_BODY_TEMPLATE = """
A bot thinks this mirror is unhealthy because: {}.

Check it out.
""".strip()

#############################
# argument-controlled state #
#############################
LOG_ONLY = False


@dataclass
class Mirror:
  # Static info about the mirror.
  repo_url: str
  # The name of the package repo. e.g. main, root, x11
  repo_name: str
  weight: int

  # Mirror-checking state.
  next_check: datetime
  # Number of times in a row we've failed to successfully get the release file and parse
  # a sync time.
  consecutive_check_failures: int
  # The last time we were able to get and parse the mirror's release file. None means we
  # have never done that.
  last_successful_check: Optional[datetime]
  # The last sync time reported by the last successful pull and parse of the mirror's
  # release file. None means we have never done that.
  last_sync_time: Optional[datetime]

  def is_authoritative(self) -> bool:
    """Mirror freshness needs to be determined against an authoritative mirror, not the
    current wall time - it's normal for repos to sometimes go longer than the staleness
    limit without there being any new data.

    All mirrors are equal from a client perpective, so this program has secret knowledge
    of which mirrors are authoritative."""
    return self.repo_url.startswith("https://packages.termux.dev")


def clone_or_update_termux_tools_repo() -> None:
  """Call while in the workdir. We have a recent commit of termux-tools after this
  returns."""
  if os.path.exists(TERMUX_TOOLS_REPO):
    os.chdir(TERMUX_TOOLS_REPO)
    git("clean", "-dfx")
    git("pull")
  else:
    git("clone", f"https://github.com/termux/{TERMUX_TOOLS_REPO}")
    os.chdir(TERMUX_TOOLS_REPO)
  os.chdir("..")


def check_time(delay: Optional[timedelta] = None) -> datetime:
  """Chooses a time to check something. Jittered.

  If no delay is passed, defaults to the configured interval."""
  if not delay:
    delay = CHECK_INTERVAL

  # Choose a jitter factor in [-1, 1).
  jitter = ((random.random() * 2) - 1) * (delay * CHECK_JITTER_FRACTION)
  return datetime.now(UTC) + delay + jitter


def load_mirrors_from_file(filepath: str) -> list[Mirror]:
  """Creates Mirrors for each repo in the mirror definition file at the given path."""
  mirrors: list[Mirror] = []
  repos: dict[str, str] = {}
  weight = -1
  with open(filepath) as f:
    for line in f:
      if line.strip().startswith("#"):
        continue
      var, val = line.strip().split("=")
      match var:
        case "WEIGHT":
          weight = int(val)
        case _:
          repos[var.lower()] = val.strip('"')
  for repo_name, repo_url in repos.items():
    mirrors.append(
      Mirror(
        repo_url=repo_url,
        repo_name=repo_name,
        weight=int(weight),
        next_check=check_time(INITIAL_CHECK_DELAY),
        consecutive_check_failures=0,
        last_successful_check=None,
        last_sync_time=None,
      )
    )
  logging.debug(f"loaded from {filepath}, mirrors={mirrors}")
  return mirrors


def load_mirrors_from_repo() -> list[Mirror]:
  """Creates Mirrors for each (termux package) repo in the (termux-tools git) repo.
  Assumes $PWD contains the (termux-tools git) repo."""
  mirrors: list[Mirror] = []
  mirror_dir = f"{TERMUX_TOOLS_REPO}/mirrors"
  for group in os.listdir(mirror_dir):
    group_dir = f"{mirror_dir}/{group}"
    if not os.path.isdir(group_dir):
      continue
    for mirror_domain in os.listdir(group_dir):
      mirror_file = f"{group_dir}/{mirror_domain}"
      mirrors.extend(load_mirrors_from_file(mirror_file))
  logging.info(f"loaded {len(mirrors)} mirrors from repo")
  logging.debug(f"mirrors={mirrors}")
  return mirrors


def extract_authoritative_mirrors(mirrors: list[Mirror]) -> dict[str, Mirror]:
  """Takes a list of mirrors and extracts the authoritative ones for each repo.

  Returns a dict mapping repo names (e.g. "main") to the appropriate Mirrors."""
  authorities = {}
  for mirror in mirrors:
    if mirror.is_authoritative():
      # We need a bunch more code to do anything sensible if we believe in multiple
      # authorities.
      assert mirror.repo_name not in authorities
      authorities[mirror.repo_name] = mirror
  logging.info(f"extracted authoritative mirrors: {authorities}")
  return authorities


def check_and_update_mirror(mirror: Mirror) -> Mirror:
  """Retrieve the given mirror's release file and parse a last sync time out of it.
  Update the state in the Mirror with our success or failure. Returns the same Mirror
  object that was passed in, but only so the type checker will yell if this doesn't
  explicitly signal failure or success."""

  def fail(mirror) -> Mirror:
    mirror.consecutive_check_failures += 1
    mirror.next_check = check_time()
    return mirror

  def succeed(mirror, sync_time, release_url) -> Mirror:
    mirror.last_successful_check = datetime.now(UTC)
    mirror.last_sync_time = sync_time
    mirror.consecutive_check_failures = 0
    mirror.next_check = check_time()
    logging.info(f"successfully retrieved {release_url}")
    logging.debug(f"mirror={mirror}")
    return mirror

  repo_path = "stable" if mirror.repo_name == "main" else mirror.repo_name
  release_url = f"{mirror.repo_url}/dists/{repo_path}/Release"
  start = time.monotonic()
  try:
    release_req = requests.get(release_url, timeout=RELEASE_RETRIEVAL_LIMIT_S)
  except requests.exceptions.ConnectionError:
    if time.monotonic() - start > RELEASE_RETRIEVAL_LIMIT_S:
      logging.error(f"connect timeout for {release_url}")
    else:
      logging.error(f"connect failure for {release_url}")
    logging.debug(f"mirror={mirror}")
    return fail(mirror)
  except (requests.exceptions.ReadTimeout, urllib3.exceptions.ReadTimeoutError):
    logging.error(f"read timeout for {release_url}")
    return fail(mirror)
  if release_req.status_code != 200:
    logging.warning(f"retrieving {release_url} returned HTTP {release_req.status_code}")
    logging.debug(f"mirror={mirror}")
    return fail(mirror)

  for line in release_req.text.splitlines():
    if line.startswith("Date:"):
      # This is a sync time. line looks like this: "Date: Wed, 28 May 2025 06:20:22 UTC"
      # Assumes:
      #   it's always UTC, which might not be true
      #   it uses abbreviated month names, which isn't easy to confirm because I'm
      #     writing this in May
      try:
        sync_time_str = line.strip("Date: ").rstrip(" UTC").split(", ")[1]
        sync_time = datetime.fromtimestamp(
          datetime.strptime(sync_time_str, "%d %b %Y %H:%M:%S").timestamp(), UTC
        )
        return succeed(mirror, sync_time, release_url)
      except ValueError:
        logging.exception(
          f"retrieved release file at {release_url}, but couldn't parse the sync time"
        )
        logging.debug(f"mirror={mirror}")
        return fail(mirror)

  # We didn't find a sync time in the release file. Treat this as a failure.
  logging.error(
    f"retrieved release file at {release_url}, but couldn't find a sync time"
  )
  logging.debug(f"mirror={mirror}")
  return fail(mirror)


def file_github_issue(title, message) -> None:
  """Create an issue in the configured repo, if there isn't already an open one with the
  given title."""
  if LOG_ONLY:
    logging.warn(f"would create issue, but running log-only:\n{title}\n{message}")
    return

  try:
    open_issues = list_open_issues(REPORTING_REPO)
    if title in open_issues.keys():
      url = open_issues[title]
      logging.info(f"existing issue: {url}")
      return

    issue_url = open_new_issue(REPORTING_REPO, title, message)
    logging.warn(f"created issue {issue_url}")
  except (ValueError, sh.ErrorReturnCode):
    logging.exception(
      "something went wrong communicating with github - no issue created"
    )


def judge_mirror(mirror: Mirror, authority: Optional[Mirror]) -> None:
  """Decide if a mirror looks unhealthy and do something useful if it does."""
  # If we're trying to judge an authority, it's a bug.
  assert not mirror.is_authoritative()

  # We need to know if we are failing to monitor the mirror.
  if mirror.consecutive_check_failures > CONSECUTIVE_FAIL_LIMIT:
    file_github_issue(
      ISSUE_TITLE_TEMPLATE.format(mirror.repo_url),
      ISSUE_BODY_TEMPLATE.format(
        f"checking it failed {mirror.consecutive_check_failures} times in a row"
      ),
    )
    return

  # Failure to determine the sync time is counted in consecutive failures, and authority
  # freshness needs to be handled separately. It's okay do nothing if we don't have
  # enough info to do anything else where.
  if not mirror.last_sync_time or not authority or not authority.last_sync_time:
    return

  # This is the freshness check we're all here for.
  if authority.last_sync_time - mirror.last_sync_time > STALENESS_LIMIT:
    file_github_issue(
      ISSUE_TITLE_TEMPLATE.format(mirror.repo_url),
      ISSUE_BODY_TEMPLATE.format(f"it hasn't synced since {mirror.last_sync_time}"),
    )


def check_mirrors_forever(
  mirrors: list[Mirror], authorities: dict[str, Mirror]
) -> None:
  while True:
    time.sleep(0.1)
    now = datetime.now(UTC)
    for mirror in mirrors:
      if mirror.next_check < now:
        _ = check_and_update_mirror(mirror)

        # TODO: Authorities need essentially distinct logic and reporting.
        if not mirror.is_authoritative():
          authority = authorities.get(mirror.repo_name)
          if not authority:
            logging.warning(
              f"unable to determine authority for repo_name={mirror.repo_name}"
            )
          judge_mirror(mirror, authority)


def main() -> None:
  global LOG_ONLY

  logging.basicConfig(level=logging.INFO)

  parser = argparse.ArgumentParser()
  parser.add_argument(
    "--log-only", default=False, help="Don't touch github. If a repo is bad, just log."
  )
  parser.add_argument("WORKDIR")
  args = parser.parse_args()
  if args.log_only:
    logging.warn("running in log-only mode")
    LOG_ONLY = True
  os.chdir(args.WORKDIR)

  clone_or_update_termux_tools_repo()
  mirrors = load_mirrors_from_repo()
  authorities = extract_authoritative_mirrors(mirrors)

  # Authorities remain in the all-mirrors list so we can monitor them with the same
  # logic as secondaries, but we can avoid some log noise by making sure they're checked
  # first.
  for mirror in mirrors:
    if mirror.is_authoritative():
      mirror.next_check = datetime.fromtimestamp(0, UTC)
  mirrors.sort(key=lambda m: m.next_check)
  check_mirrors_forever(mirrors, authorities)


if __name__ == "__main__":
  try:
    main()
  except KeyboardInterrupt:
    pass
